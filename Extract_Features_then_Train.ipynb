{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet201\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2, os, os, git, glob, random\n",
    "import numpy as np\n",
    "from insectrec.utils import get_dataset, train_generator, valid_generator, augment_trainset\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "created_data_path = f'{repo.working_tree_dir}/insectrec/created_data'\n",
    "path_impy_crops_export = f'{created_data_path}/impy_crops_export/'\n",
    "path_images_augmented = f'{created_data_path}/images_augmented/'\n",
    "\n",
    "if not os.path.isdir(path_images_augmented):\n",
    "    raise NotImplemented(\"Not expanded dataset yet!\")\n",
    "\n",
    "batch_size = 128\n",
    "img_dim = 90\n",
    "modelname = 'xtract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating le for encoding labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Creating dataframe with all the original data (x: filenames, textlabels, y: nummerical labels)\n",
    "df_orig = pd.DataFrame()\n",
    "df_orig['x'] = pd.Series(glob.glob(f\"{path_impy_crops_export}/*/*.jpg\"))\n",
    "df_orig['y_text'] = df_orig['x'].apply(lambda x: x.split('/')[-2])\n",
    "df_orig['y'] = le.fit_transform(df_orig.y_text)\n",
    "\n",
    "# Splitting into train/val/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_orig.x, df_orig.y, test_size=0.2, random_state=seed, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering info on augmented X_train data\n",
    "df_aug = pd.DataFrame()\n",
    "df_aug['x'] = pd.Series(glob.glob(f\"{path_images_augmented}/*/*.jpg\"))\n",
    "df_aug['textlabels'] = df_aug['x'].apply(lambda x: x.split('/')[-2])\n",
    "df_aug['y'] = le.fit_transform(df_aug.textlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug = df_aug.x.tolist()\n",
    "y_train_aug = df_aug.y.tolist()\n",
    "\n",
    "c = list(zip(X_train_aug, y_train_aug))\n",
    "random.shuffle(c)\n",
    "X_train_aug, y_train_aug = zip(*c)\n",
    "X_train_aug = list(X_train_aug)\n",
    "y_train_aug = list(y_train_aug)\n",
    "X_val = X_val.tolist()\n",
    "y_val = y_val.tolist()\n",
    "X_test = X_test.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'global_average_pooling2d/Identity:0' shape=(None, 1024) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = DenseNet121(include_top=False,\n",
    "                         weights='imagenet', \n",
    "                        input_shape=(img_dim,img_dim,3))\n",
    "x = base_model.output\n",
    "predictions = GlobalAveragePooling2D()(x)\n",
    "# # x = Dense(128, activation='relu')(x)\n",
    "# # x = Dropout(0.5)(x)\n",
    "# # predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/305 [==============================] - 32s 103ms/step\n"
     ]
    }
   ],
   "source": [
    "X_pred_aug = model.predict_generator(valid_generator(X_train_aug, y_train_aug, batch_size=batch_size, nb_classes=6, img_dim=img_dim), \n",
    "                         steps= len(X_train_aug) / batch_size, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39104, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(X_pred_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using extracted features with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, classification_report, make_scorer, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = KNeighborsClassifier(n_neighbors=11, weights='uniform',metric='manhattan', n_jobs=8)\n",
    "estimator = XGBClassifier(n_estimators=100,\n",
    "                          learning_rate=0.2,\n",
    "                          random_state=seed,\n",
    "                          seed=seed,\n",
    "                          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed: 10.6min finished\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(estimator, X_pred_aug, y_train_aug, cv=3, \n",
    "                            return_estimator=True, \n",
    "                            return_train_score=True, \n",
    "                            scoring=make_scorer(balanced_accuracy_score),\n",
    "                            verbose=1, \n",
    "                            n_jobs=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([632.42982006, 626.28758836, 628.74749184]),\n",
       " 'score_time': array([0.3916595 , 0.46820498, 0.4299686 ]),\n",
       " 'estimator': (XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "                learning_rate=0.2, max_delta_step=0, max_depth=3,\n",
       "                min_child_weight=1, missing=nan, n_estimators=100, n_jobs=1,\n",
       "                nthread=None, objective='multi:softprob', random_state=42,\n",
       "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "                silent=None, subsample=1, verbose=True, verbosity=1),\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "                learning_rate=0.2, max_delta_step=0, max_depth=3,\n",
       "                min_child_weight=1, missing=nan, n_estimators=100, n_jobs=1,\n",
       "                nthread=None, objective='multi:softprob', random_state=42,\n",
       "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "                silent=None, subsample=1, verbose=True, verbosity=1),\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "                learning_rate=0.2, max_delta_step=0, max_depth=3,\n",
       "                min_child_weight=1, missing=nan, n_estimators=100, n_jobs=1,\n",
       "                nthread=None, objective='multi:softprob', random_state=42,\n",
       "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "                silent=None, subsample=1, verbose=True, verbosity=1)),\n",
       " 'test_score': array([0.64603828, 0.64456272, 0.64402986]),\n",
       " 'train_score': array([0.74158622, 0.73956866, 0.74776989])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/18 [==============================] - 2s 118ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test_pred = model.predict_generator(valid_generator(X_test, y_test, batch_size=batch_size, nb_classes=6, img_dim=img_dim), \n",
    "                         steps= len(X_test) / batch_size, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6339795463427188"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test,cv_results['estimator'][0].predict(X_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('objdetect': conda)",
   "language": "python",
   "name": "python37664bitobjdetectconda73730bfb74724935b9013e8a9503c070"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
