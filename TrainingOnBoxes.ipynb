{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet201\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2, os, os, git, glob, random\n",
    "import numpy as np\n",
    "from insectrec.utils import get_dataset, train_generator, valid_generator, augment_trainset\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "created_data_path = f'{repo.working_tree_dir}/insectrec/created_data'\n",
    "path_impy_crops_export = f'{created_data_path}/impy_crops_export/'\n",
    "path_images_augmented = f'{created_data_path}/images_augmented/'\n",
    "\n",
    "if not os.path.isdir(path_images_augmented):\n",
    "    os.mkdir(path)\n",
    "    \n",
    "clean = True\n",
    "if clean:\n",
    "    os.system(f'rm -rf {path_images_augmented}*')\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "monitor='val_loss'\n",
    "es_patience=7\n",
    "rlr_patience=4\n",
    "img_dim = 85\n",
    "modelname = 'new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating le for encoding labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Creating dataframe with all the original data (x: filenames, textlabels, y: nummerical labels)\n",
    "df_orig = pd.DataFrame()\n",
    "df_orig['x'] = pd.Series(glob.glob(f\"{path_impy_crops_export}/*/*.jpg\"))\n",
    "df_orig['y_text'] = df_orig['x'].apply(lambda x: x.split('/')[-2])\n",
    "df_orig['y'] = le.fit_transform(df_orig.y_text)\n",
    "\n",
    "# Splitting into train/val/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_orig.x, df_orig.y, test_size=0.2, random_state=seed, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loading images...\n",
      "Finished augmentation in 100 batches of 400\n"
     ]
    }
   ],
   "source": [
    "augment_trainset(X_train=X_train, y_train=y_train, \n",
    "                 aug_imgs_path=path_images_augmented, \n",
    "                 nb_batches=100, \n",
    "                 batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering info on augmented X_train data\n",
    "df_aug = pd.DataFrame()\n",
    "df_aug['x'] = pd.Series(glob.glob(f\"{path_images_augmented}/*/*.jpg\"))\n",
    "df_aug['textlabels'] = df_aug['x'].apply(lambda x: x.split('/')[-2])\n",
    "df_aug['y'] = le.fit_transform(df_aug.textlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug = df_aug.x.tolist()\n",
    "y_train_aug = df_aug.y.tolist()\n",
    "\n",
    "c = list(zip(X_train_aug, y_train_aug))\n",
    "random.shuffle(c)\n",
    "X_train_aug, y_train_aug = zip(*c)\n",
    "X_train_aug = list(X_train_aug)\n",
    "y_train_aug = list(y_train_aug)\n",
    "X_val = X_val.tolist()\n",
    "y_val = y_val.tolist()\n",
    "X_test = X_test.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './insectrec/created_data/logs/'\n",
    "top_weights_path = f'./insectrec/created_data/weights/model_{modelname}_{img_dim}.h5'\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(monitor =  monitor,\n",
    "                                  filepath =  top_weights_path,\n",
    "                                  save_best_only = False,\n",
    "                                  save_weights_only = False,\n",
    "                                  verbose = 1),\n",
    "                  EarlyStopping(monitor =  monitor,\n",
    "                                patience =  es_patience,\n",
    "                                verbose = 1),\n",
    "                  ReduceLROnPlateau(monitor =  monitor,\n",
    "                                    factor = 0.1,\n",
    "                                    patience =  rlr_patience,\n",
    "                                    verbose = 1),\n",
    "                # CSVLogger(filename =  logfile),\n",
    "                  TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(include_top=True, weights=None, \n",
    "                        input_shape=(img_dim,img_dim,3))\n",
    "x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.001)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1239/1240 [============================>.] - ETA: 0s - loss: 1.6241 - accuracy: 0.3425\n",
      "Epoch 00001: saving model to ./insectrec/created_data/weights/model_new_85.h5\n",
      "1240/1240 [==============================] - 425s 343ms/step - loss: 1.6240 - accuracy: 0.3426 - val_loss: 1.5691 - val_accuracy: 0.3480\n",
      "Epoch 2/100\n",
      "1239/1240 [============================>.] - ETA: 0s - loss: 1.5521 - accuracy: 0.3634\n",
      "Epoch 00002: saving model to ./insectrec/created_data/weights/model_new_85.h5\n",
      "1240/1240 [==============================] - 423s 341ms/step - loss: 1.5521 - accuracy: 0.3634 - val_loss: 1.4537 - val_accuracy: 0.4585\n",
      "Epoch 3/100\n",
      "1239/1240 [============================>.] - ETA: 0s - loss: 1.4747 - accuracy: 0.4109\n",
      "Epoch 00003: saving model to ./insectrec/created_data/weights/model_new_85.h5\n",
      "1240/1240 [==============================] - 416s 336ms/step - loss: 1.4746 - accuracy: 0.4110 - val_loss: 1.4538 - val_accuracy: 0.3770\n",
      "Epoch 4/100\n",
      "1002/1240 [=======================>......] - ETA: 1:15 - loss: 1.3531 - accuracy: 0.4948"
     ]
    }
   ],
   "source": [
    "import math\n",
    "FH = model.fit_generator(train_generator(X_train_aug, y_train_aug, batch_size=batch_size, nb_classes=6, img_dim=img_dim), \n",
    "                         validation_data=valid_generator(X_val, y_val, batch_size=batch_size, nb_classes=6, img_dim=img_dim), \n",
    "                         steps_per_epoch=int(math.ceil(float(len(X_train_aug)) / float(batch_size))), \n",
    "                         validation_steps=int(math.ceil(float(len(X_val))/float(batch_size))), \n",
    "                         epochs=epochs, \n",
    "                         verbose=1, \n",
    "                         callbacks=callbacks_list, \n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common(a,b): \n",
    "    c = [value for value in a if value in b] \n",
    "    return c\n",
    "\n",
    "common(X_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = DenseNet121(include_top=False, weights='imagenet', \n",
    "#                          input_shape=(img_dim,img_dim,3))\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # let's visualize layer names and layer indices to see how many layers\n",
    "# # we should freeze:\n",
    "# #for i, layer in enumerate(base_model.layers):\n",
    "# #   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model on the new data for a few epochs\n",
    "# import math\n",
    "# FH = model.fit_generator(train_generator(X_train_aug, y_train, batch_size=batch_size, nb_classes=6, img_dim=img_dim),\n",
    "#                          validation_data=valid_generator(X_val, y_val, batch_size=batch_size, nb_classes=6, img_dim=img_dim), \n",
    "#                          steps_per_epoch=int(math.ceil(float(len(X_train_aug)) / float(batch_size))),\n",
    "#                          validation_steps=int(math.ceil(float(len(X_val))/float(batch_size))),\n",
    "#                          epochs=epochs, \n",
    "#                          verbose=1, \n",
    "#                          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# # the first 249 layers and unfreeze the rest:\n",
    "# for layer in model.layers[:425]:\n",
    "#    layer.trainable = False\n",
    "# for layer in model.layers[425:]:\n",
    "#    layer.trainable = True\n",
    "\n",
    "# # we need to recompile the model for these modifications to take effect\n",
    "# # we use SGD with a low learning rate\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# # alongside the top Dense layers\n",
    "# FH2 = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "#     validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n",
    "#     epochs=epochs, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACTING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
