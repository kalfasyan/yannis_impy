{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet201\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2, os, os, git, glob, random\n",
    "import numpy as np\n",
    "from insectrec.utils import get_dataset, train_generator, valid_generator, augment_trainset\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "created_data_path = f'{repo.working_tree_dir}/insectrec/created_data'\n",
    "path_impy_crops_export = f'{created_data_path}/impy_crops_export/'\n",
    "path_images_augmented = f'{created_data_path}/images_augmented/'\n",
    "\n",
    "if not os.path.isdir(path_images_augmented):\n",
    "    os.mkdir(path)\n",
    "    \n",
    "clean = True\n",
    "if clean:\n",
    "    os.system(f'rm -rf {path_images_augmented}*')\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "monitor='val_loss'\n",
    "es_patience=7\n",
    "rlr_patience=4\n",
    "img_dim = 90\n",
    "modelname = 'fuji'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating le for encoding labels\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Creating dataframe with all the original data (x: filenames, textlabels, y: nummerical labels)\n",
    "df_orig = pd.DataFrame()\n",
    "df_orig['x'] = pd.Series(glob.glob(f\"{path_impy_crops_export}/*/*.jpg\"))\n",
    "df_orig['y_text'] = df_orig['x'].apply(lambda x: x.split('/')[-2])\n",
    "df_orig['y'] = le.fit_transform(df_orig.y_text)\n",
    "\n",
    "# Splitting into train/val/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_orig.x, df_orig.y, test_size=0.2, random_state=seed, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading image data and assigning labels...\n",
      "Normalizing data by dividing by 255.\n",
      "Creating an ImageDataGenerator.\n",
      "Creating directories for each class.\n",
      "Fitting data generator on data.\n",
      "Expanding dataset by using generator's flow method on data/labels.\n",
      "using batch_size of 400\n",
      "Finished augmentation in 100 batches of 400\n"
     ]
    }
   ],
   "source": [
    "augment_trainset(X_train=X_train, y_train=y_train, \n",
    "                 aug_imgs_path=path_images_augmented, \n",
    "                 nb_batches=100, \n",
    "                 batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering info on augmented X_train data\n",
    "df_aug = pd.DataFrame()\n",
    "df_aug['x'] = pd.Series(glob.glob(f\"{path_images_augmented}/*/*.jpg\"))\n",
    "df_aug['textlabels'] = df_aug['x'].apply(lambda x: x.split('/')[-2])\n",
    "df_aug['y'] = le.fit_transform(df_aug.textlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug = df_aug.x.tolist()\n",
    "y_train_aug = df_aug.y.tolist()\n",
    "\n",
    "c = list(zip(X_train_aug, y_train_aug))\n",
    "random.shuffle(c)\n",
    "X_train_aug, y_train_aug = zip(*c)\n",
    "X_train_aug = list(X_train_aug)\n",
    "y_train_aug = list(y_train_aug)\n",
    "X_val = X_val.tolist()\n",
    "y_val = y_val.tolist()\n",
    "X_test = X_test.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './insectrec/created_data/logs/'\n",
    "top_weights_path = f'./insectrec/created_data/weights/model_{modelname}_{img_dim}.h5'\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(monitor =  monitor,\n",
    "                                  filepath =  top_weights_path,\n",
    "                                  save_best_only = False,\n",
    "                                  save_weights_only = False,\n",
    "                                  verbose = 1),\n",
    "                  EarlyStopping(monitor =  monitor,\n",
    "                                patience =  es_patience,\n",
    "                                verbose = 1),\n",
    "                  ReduceLROnPlateau(monitor =  monitor,\n",
    "                                    factor = 0.1,\n",
    "                                    patience =  rlr_patience,\n",
    "                                    verbose = 1),\n",
    "                # CSVLogger(filename =  logfile),\n",
    "                  TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(include_top=True, weights=None, \n",
    "                        input_shape=(img_dim,img_dim,3))\n",
    "x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.001)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "FH = model.fit_generator(train_generator(X_train_aug, y_train_aug, batch_size=batch_size, nb_classes=6, img_dim=img_dim), \n",
    "                         validation_data=valid_generator(X_val, y_val, batch_size=batch_size, nb_classes=6, img_dim=img_dim), \n",
    "                         steps_per_epoch=int(math.ceil(float(len(X_train_aug)) / float(batch_size))), \n",
    "                         validation_steps=int(math.ceil(float(len(X_val))/float(batch_size))), \n",
    "                         epochs=epochs, \n",
    "                         verbose=1, \n",
    "                         callbacks=callbacks_list, \n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common(a,b): \n",
    "    c = [value for value in a if value in b] \n",
    "    return c\n",
    "\n",
    "common(X_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8576"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = DenseNet121(include_top=False, weights='imagenet', \n",
    "#                          input_shape=(img_dim,img_dim,3))\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # let's visualize layer names and layer indices to see how many layers\n",
    "# # we should freeze:\n",
    "# #for i, layer in enumerate(base_model.layers):\n",
    "# #   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model on the new data for a few epochs\n",
    "# import math\n",
    "# FH = model.fit_generator(train_generator(X_train_aug, y_train, batch_size=batch_size, nb_classes=6, img_dim=img_dim),\n",
    "#                          validation_data=valid_generator(X_val, y_val, batch_size=batch_size, nb_classes=6, img_dim=img_dim), \n",
    "#                          steps_per_epoch=int(math.ceil(float(len(X_train_aug)) / float(batch_size))),\n",
    "#                          validation_steps=int(math.ceil(float(len(X_val))/float(batch_size))),\n",
    "#                          epochs=epochs, \n",
    "#                          verbose=1, \n",
    "#                          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# # the first 249 layers and unfreeze the rest:\n",
    "# for layer in model.layers[:425]:\n",
    "#    layer.trainable = False\n",
    "# for layer in model.layers[425:]:\n",
    "#    layer.trainable = True\n",
    "\n",
    "# # we need to recompile the model for these modifications to take effect\n",
    "# # we use SGD with a low learning rate\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# # alongside the top Dense layers\n",
    "# FH2 = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "#     validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n",
    "#     epochs=epochs, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACTING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
