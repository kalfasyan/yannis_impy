{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from pyimagesearch.lenet import LeNet\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "monitor='val_loss'\n",
    "es_patience=7\n",
    "rlr_patience=3\n",
    "img_width, img_height = 60,60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loading images...\n",
      " loading images...\n"
     ]
    }
   ],
   "source": [
    "def get_dataset(dataset='./insectrec/created_data/impy_crops_export/'):\n",
    "    # initialize the data and labels\n",
    "    print(\" loading images...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # grab the image paths and randomly shuffle them\n",
    "    imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "    random.seed(42)\n",
    "    random.shuffle(imagePaths)\n",
    "\n",
    "    # loop over the input images\n",
    "    for imagePath in imagePaths:\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.resize(image, (img_width, img_height))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "\n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        labels.append(label)\n",
    "\n",
    "    # scale the raw pixel intensities to the range [0, 1]\n",
    "    data = np.array(data, dtype=\"float\") / 255.0\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "\n",
    "    # partition the data into training and testing splits using 75% of\n",
    "    # the data for training and the remaining 25% for testing\n",
    "    (trainX, testX, trainY, testY) = train_test_split(data,\n",
    "        labels, test_size=0.2, random_state=42)\n",
    "    return trainX, testX, trainY, testY, labels\n",
    "\n",
    "_, testX, _, testY, _ = get_dataset(dataset='./insectrec/created_data/impy_crops_export/')\n",
    "trainX, _, trainY, _, labels = get_dataset(dataset='./insectrec/created_data/images_augmented/')\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=6)\n",
    "testY = to_categorical(testY, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, zoom_range=0.3,\n",
    "    horizontal_flip=True, vertical_flip=True,fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "log_dir = './insectrec/created_data/logs/'\n",
    "top_weights_path = './insectrec/created_data/weights/'\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(monitor =  monitor,\n",
    "                                  filepath =  top_weights_path,\n",
    "                                  save_best_only = True,\n",
    "                                  save_weights_only = False,\n",
    "                                  verbose = 1),\n",
    "                  EarlyStopping(monitor =  monitor,\n",
    "                                patience =  es_patience,\n",
    "                                verbose = 1),\n",
    "                  ReduceLROnPlateau(monitor =  monitor,\n",
    "                                    factor = 0.1,\n",
    "                                    patience =  rlr_patience,\n",
    "                                    verbose = 1),\n",
    "                # CSVLogger(filename =  logfile),\n",
    "                  TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(include_top=True, weights=None, \n",
    "                         input_shape=(img_width,img_height,3))\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(256, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 424/1910 [=====>........................] - ETA: 25:38 - loss: 1.5330 - accuracy: 0.3841"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "FH = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n",
    "    epochs=epochs, verbose=1, max_queue_size=100, workers=16, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "439/439 [==============================] - 418s 953ms/step - loss: 1.4824 - accuracy: 0.4256 - val_loss: 1.6483 - val_accuracy: 0.3299\n",
      "Epoch 2/5\n",
      "439/439 [==============================] - 429s 978ms/step - loss: 1.3466 - accuracy: 0.4812 - val_loss: 1.5725 - val_accuracy: 0.3507\n",
      "Epoch 3/5\n",
      "439/439 [==============================] - 421s 958ms/step - loss: 1.3114 - accuracy: 0.4903 - val_loss: 1.5725 - val_accuracy: 0.3720\n",
      "Epoch 4/5\n",
      "439/439 [==============================] - 425s 969ms/step - loss: 1.2864 - accuracy: 0.4989 - val_loss: 1.6181 - val_accuracy: 0.3567\n",
      "Epoch 5/5\n",
      "439/439 [==============================] - 419s 955ms/step - loss: 1.2537 - accuracy: 0.5227 - val_loss: 1.5375 - val_accuracy: 0.3857\n"
     ]
    }
   ],
   "source": [
    "base_model = DenseNet121(include_top=False, weights='imagenet', \n",
    "                         input_shape=(img_width,img_height,3))\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(256, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n",
    "    epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "438/439 [============================>.] - ETA: 0s - loss: 1.2460 - accuracy: 0.5206\n",
      "Epoch 00001: val_loss improved from inf to 1.70719, saving model to ./insectrec/created_data/weights/\n",
      "WARNING:tensorflow:From /home/kalfasyan/anaconda3/envs/objdetect/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./insectrec/created_data/weights/assets\n",
      "439/439 [==============================] - 471s 1s/step - loss: 1.2453 - accuracy: 0.5208 - val_loss: 1.7072 - val_accuracy: 0.3882\n",
      "Epoch 2/100\n",
      "438/439 [============================>.] - ETA: 0s - loss: 1.1642 - accuracy: 0.5574\n",
      "Epoch 00002: val_loss did not improve from 1.70719\n",
      "439/439 [==============================] - 454s 1s/step - loss: 1.1641 - accuracy: 0.5574 - val_loss: 1.8167 - val_accuracy: 0.3771\n",
      "Epoch 3/100\n",
      "438/439 [============================>.] - ETA: 0s - loss: 1.1157 - accuracy: 0.5753\n",
      "Epoch 00003: val_loss improved from 1.70719 to 1.54660, saving model to ./insectrec/created_data/weights/\n",
      "INFO:tensorflow:Assets written to: ./insectrec/created_data/weights/assets\n",
      "439/439 [==============================] - 478s 1s/step - loss: 1.1150 - accuracy: 0.5755 - val_loss: 1.5466 - val_accuracy: 0.3734\n",
      "Epoch 4/100\n",
      "438/439 [============================>.] - ETA: 0s - loss: 1.0881 - accuracy: 0.5848\n",
      "Epoch 00004: val_loss did not improve from 1.54660\n",
      "439/439 [==============================] - 454s 1s/step - loss: 1.0885 - accuracy: 0.5846 - val_loss: 1.7591 - val_accuracy: 0.3976\n",
      "Epoch 5/100\n",
      "438/439 [============================>.] - ETA: 0s - loss: 1.0744 - accuracy: 0.5934\n",
      "Epoch 00005: val_loss did not improve from 1.54660\n",
      "439/439 [==============================] - 449s 1s/step - loss: 1.0748 - accuracy: 0.5933 - val_loss: 1.5584 - val_accuracy: 0.3996\n",
      "Epoch 6/100\n",
      "438/439 [============================>.] - ETA: 0s - loss: 1.0578 - accuracy: 0.5995\n",
      "Epoch 00006: val_loss did not improve from 1.54660\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "439/439 [==============================] - 443s 1s/step - loss: 1.0574 - accuracy: 0.5994 - val_loss: 1.7770 - val_accuracy: 0.3700\n",
      "Epoch 7/100\n",
      "438/439 [============================>.] - ETA: 0s - loss: 1.0182 - accuracy: 0.6129\n",
      "Epoch 00007: val_loss did not improve from 1.54660\n",
      "439/439 [==============================] - 446s 1s/step - loss: 1.0183 - accuracy: 0.6128 - val_loss: 1.8363 - val_accuracy: 0.3717\n",
      "Epoch 8/100\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.9971 - accuracy: 0.6282\n",
      "Epoch 00008: val_loss did not improve from 1.54660\n",
      "439/439 [==============================] - 456s 1s/step - loss: 0.9972 - accuracy: 0.6283 - val_loss: 1.8330 - val_accuracy: 0.3714\n",
      "Epoch 9/100\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.9817 - accuracy: 0.6307\n",
      "Epoch 00009: val_loss did not improve from 1.54660\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "439/439 [==============================] - 452s 1s/step - loss: 0.9816 - accuracy: 0.6308 - val_loss: 1.8458 - val_accuracy: 0.3649\n",
      "Epoch 10/100\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.9774 - accuracy: 0.6301\n",
      "Epoch 00010: val_loss did not improve from 1.54660\n",
      "439/439 [==============================] - 454s 1s/step - loss: 0.9773 - accuracy: 0.6298 - val_loss: 1.8198 - val_accuracy: 0.3703\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first L layers and unfreeze the rest:\n",
    "L = 313\n",
    "for layer in model.layers[:L]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[L:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "optimizer= SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "FH = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n",
    "    epochs=epochs, verbose=1, max_queue_size=40, workers=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
