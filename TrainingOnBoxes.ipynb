{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet201\n",
    " \n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from pyimagesearch.lenet import LeNet\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "monitor='val_loss'\n",
    "es_patience=7\n",
    "rlr_patience=3\n",
    "img_width, img_height = 65,65\n",
    "modelname = 'testnopretune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loading images...\n",
      " loading images...\n"
     ]
    }
   ],
   "source": [
    "def get_dataset(dataset='./insectrec/created_data/impy_crops_export/'):\n",
    "    # initialize the data and labels\n",
    "    print(\" loading images...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # grab the image paths and randomly shuffle them\n",
    "    imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "    random.seed(42)\n",
    "    random.shuffle(imagePaths)\n",
    "\n",
    "    # loop over the input images\n",
    "    for imagePath in imagePaths:\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (img_width, img_height))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "\n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        labels.append(label)\n",
    "\n",
    "    # scale the raw pixel intensities to the range [0, 1]\n",
    "    data = np.array(data, dtype=\"float\") / 255.0\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "\n",
    "    # partition the data into training and testing splits using 75% of\n",
    "    # the data for training and the remaining 25% for testing\n",
    "    (trainX, testX, trainY, testY) = train_test_split(data,\n",
    "        labels, test_size=0.2, random_state=42)\n",
    "    return trainX, testX, trainY, testY, labels\n",
    "\n",
    "_, testX, _, testY, _ = get_dataset(dataset='./insectrec/created_data/impy_crops_export/')\n",
    "trainX, _, trainY, _, labels = get_dataset(dataset='./insectrec/created_data/images_augmented/')\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=6)\n",
    "testY = to_categorical(testY, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3516, 65, 65, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(testX[208])\n",
    "plt.show()\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator()\n",
    "#     rotation_range=30, width_shift_range=0.1,\n",
    "#     height_shift_range=0.1, zoom_range=0.3,\n",
    "#     horizontal_flip=True, vertical_flip=True,fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './insectrec/created_data/logs/'\n",
    "top_weights_path = f'./insectrec/created_data/weights/model_{modelname}_{img_width}.h5'\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(monitor =  monitor,\n",
    "                                  filepath =  top_weights_path,\n",
    "                                  save_best_only = False,\n",
    "                                  save_weights_only = False,\n",
    "                                  verbose = 1),\n",
    "                  EarlyStopping(monitor =  monitor,\n",
    "                                patience =  es_patience,\n",
    "                                verbose = 1),\n",
    "                  ReduceLROnPlateau(monitor =  monitor,\n",
    "                                    factor = 0.1,\n",
    "                                    patience =  rlr_patience,\n",
    "                                    verbose = 1),\n",
    "                # CSVLogger(filename =  logfile),\n",
    "                  TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = DenseNet121(include_top=True, weights=None, \n",
    "#                         input_shape=(img_width,img_height,3))\n",
    "#x = base_model.output\n",
    "#predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "#model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FH = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "#    validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n",
    "#    epochs=epochs, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(include_top=False, weights='imagenet', \n",
    "                         input_shape=(img_width,img_height,3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "#for i, layer in enumerate(base_model.layers):\n",
    "#   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.2415 - accuracy: 0.5576\n",
      "Epoch 00001: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1761s 1s/step - loss: 1.2414 - accuracy: 0.5576 - val_loss: 1.4414 - val_accuracy: 0.5398\n",
      "Epoch 2/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.1839 - accuracy: 0.5739\n",
      "Epoch 00002: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1765s 1s/step - loss: 1.1842 - accuracy: 0.5738 - val_loss: 1.5003 - val_accuracy: 0.4858\n",
      "Epoch 3/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.1984 - accuracy: 0.5929\n",
      "Epoch 00003: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1766s 1s/step - loss: 1.1987 - accuracy: 0.5928 - val_loss: 3.9295 - val_accuracy: 0.3817\n",
      "Epoch 4/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.0561 - accuracy: 0.6215\n",
      "Epoch 00004: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1765s 1s/step - loss: 1.0566 - accuracy: 0.6214 - val_loss: 0.9551 - val_accuracy: 0.6496\n",
      "Epoch 5/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.0258 - accuracy: 0.6385\n",
      "Epoch 00005: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1767s 1s/step - loss: 1.0259 - accuracy: 0.6385 - val_loss: 0.9254 - val_accuracy: 0.6581\n",
      "Epoch 6/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.0555 - accuracy: 0.6373\n",
      "Epoch 00006: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1765s 1s/step - loss: 1.0554 - accuracy: 0.6373 - val_loss: 1.4852 - val_accuracy: 0.5171\n",
      "Epoch 7/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.2604 - accuracy: 0.6107\n",
      "Epoch 00007: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1767s 1s/step - loss: 1.2603 - accuracy: 0.6107 - val_loss: 0.9535 - val_accuracy: 0.6675\n",
      "Epoch 8/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.3405 - accuracy: 0.5886\n",
      "Epoch 00008: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1430/1430 [==============================] - 1765s 1s/step - loss: 1.3404 - accuracy: 0.5885 - val_loss: 1.1577 - val_accuracy: 0.5674\n",
      "Epoch 9/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9945 - accuracy: 0.6484\n",
      "Epoch 00009: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1766s 1s/step - loss: 0.9945 - accuracy: 0.6484 - val_loss: 0.8709 - val_accuracy: 0.6834\n",
      "Epoch 10/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.0145 - accuracy: 0.6520\n",
      "Epoch 00010: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1768s 1s/step - loss: 1.0145 - accuracy: 0.6520 - val_loss: 0.8662 - val_accuracy: 0.6866\n",
      "Epoch 11/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9827 - accuracy: 0.6624\n",
      "Epoch 00011: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1767s 1s/step - loss: 0.9828 - accuracy: 0.6625 - val_loss: 0.8434 - val_accuracy: 0.7019\n",
      "Epoch 12/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9618 - accuracy: 0.6667\n",
      "Epoch 00012: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1766s 1s/step - loss: 0.9616 - accuracy: 0.6668 - val_loss: 0.8235 - val_accuracy: 0.7056\n",
      "Epoch 13/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9461 - accuracy: 0.6778\n",
      "Epoch 00013: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1768s 1s/step - loss: 0.9464 - accuracy: 0.6777 - val_loss: 0.8121 - val_accuracy: 0.7110\n",
      "Epoch 14/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9339 - accuracy: 0.6802\n",
      "Epoch 00014: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1764s 1s/step - loss: 0.9338 - accuracy: 0.6802 - val_loss: 0.8060 - val_accuracy: 0.7144\n",
      "Epoch 15/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9057 - accuracy: 0.6907\n",
      "Epoch 00015: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1767s 1s/step - loss: 0.9056 - accuracy: 0.6907 - val_loss: 0.7967 - val_accuracy: 0.7230\n",
      "Epoch 16/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.8794 - accuracy: 0.6980\n",
      "Epoch 00016: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1765s 1s/step - loss: 0.8794 - accuracy: 0.6980 - val_loss: 0.7903 - val_accuracy: 0.7253\n",
      "Epoch 17/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.8788 - accuracy: 0.7048\n",
      "Epoch 00017: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1776s 1s/step - loss: 0.8788 - accuracy: 0.7048 - val_loss: 0.7745 - val_accuracy: 0.7284\n",
      "Epoch 18/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.8938 - accuracy: 0.7090\n",
      "Epoch 00018: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1770s 1s/step - loss: 0.8940 - accuracy: 0.7090 - val_loss: 0.7935 - val_accuracy: 0.7244\n",
      "Epoch 19/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.8786 - accuracy: 0.7138\n",
      "Epoch 00019: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1772s 1s/step - loss: 0.8783 - accuracy: 0.7140 - val_loss: 0.8879 - val_accuracy: 0.6914\n",
      "Epoch 20/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.8219 - accuracy: 0.7217\n",
      "Epoch 00020: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1766s 1s/step - loss: 0.8217 - accuracy: 0.7217 - val_loss: 0.7557 - val_accuracy: 0.7415\n",
      "Epoch 21/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.8186 - accuracy: 0.7266\n",
      "Epoch 00021: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1767s 1s/step - loss: 0.8184 - accuracy: 0.7266 - val_loss: 0.7877 - val_accuracy: 0.7272\n",
      "Epoch 22/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.8054 - accuracy: 0.7321\n",
      "Epoch 00022: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1769s 1s/step - loss: 0.8051 - accuracy: 0.7322 - val_loss: 0.7573 - val_accuracy: 0.7440\n",
      "Epoch 23/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.7728 - accuracy: 0.7370\n",
      "Epoch 00023: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1430/1430 [==============================] - 1767s 1s/step - loss: 0.7727 - accuracy: 0.7370 - val_loss: 0.7703 - val_accuracy: 0.7375\n",
      "Epoch 24/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.7522 - accuracy: 0.7479\n",
      "Epoch 00024: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1768s 1s/step - loss: 0.7521 - accuracy: 0.7478 - val_loss: 0.7317 - val_accuracy: 0.7511\n",
      "Epoch 25/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.7373 - accuracy: 0.7485\n",
      "Epoch 00025: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1767s 1s/step - loss: 0.7371 - accuracy: 0.7485 - val_loss: 0.7470 - val_accuracy: 0.7474\n",
      "Epoch 26/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.7386 - accuracy: 0.7510\n",
      "Epoch 00026: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1770s 1s/step - loss: 0.7385 - accuracy: 0.7510 - val_loss: 0.7521 - val_accuracy: 0.7469\n",
      "Epoch 27/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.7347 - accuracy: 0.7531\n",
      "Epoch 00027: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "1430/1430 [==============================] - 1768s 1s/step - loss: 0.7346 - accuracy: 0.7531 - val_loss: 0.7320 - val_accuracy: 0.7514\n",
      "Epoch 28/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.7309 - accuracy: 0.7541\n",
      "Epoch 00028: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1770s 1s/step - loss: 0.7311 - accuracy: 0.7540 - val_loss: 0.7355 - val_accuracy: 0.7534\n",
      "Epoch 29/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.7306 - accuracy: 0.7543\n",
      "Epoch 00029: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1751s 1s/step - loss: 0.7306 - accuracy: 0.7543 - val_loss: 0.7345 - val_accuracy: 0.7517\n",
      "Epoch 30/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.7329 - accuracy: 0.7535\n",
      "Epoch 00030: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "1430/1430 [==============================] - 1771s 1s/step - loss: 0.7328 - accuracy: 0.7536 - val_loss: 0.7359 - val_accuracy: 0.7514\n",
      "Epoch 31/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.7283 - accuracy: 0.7548\n",
      "Epoch 00031: saving model to ./insectrec/created_data/weights/model_testnopretune_65.h5\n",
      "1430/1430 [==============================] - 1771s 1s/step - loss: 0.7283 - accuracy: 0.7548 - val_loss: 0.7391 - val_accuracy: 0.7534\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "#for layer in base_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "FH = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n",
    "    epochs=epochs, verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.0447 - accuracy: 0.6123\n",
      "Epoch 00001: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "1430/1430 [==============================] - 1554s 1s/step - loss: 1.0445 - accuracy: 0.6125 - val_loss: 1.6603 - val_accuracy: 0.4329\n",
      "Epoch 2/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 1.0006 - accuracy: 0.6309\n",
      "Epoch 00002: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "1430/1430 [==============================] - 1553s 1s/step - loss: 1.0006 - accuracy: 0.6309 - val_loss: 1.5855 - val_accuracy: 0.4386\n",
      "Epoch 3/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9852 - accuracy: 0.6356\n",
      "Epoch 00003: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "1430/1430 [==============================] - 1557s 1s/step - loss: 0.9853 - accuracy: 0.6356 - val_loss: 2.0392 - val_accuracy: 0.3916\n",
      "Epoch 4/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9708 - accuracy: 0.6427\n",
      "Epoch 00004: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "1430/1430 [==============================] - 1555s 1s/step - loss: 0.9707 - accuracy: 0.6427 - val_loss: 1.6541 - val_accuracy: 0.4280\n",
      "Epoch 5/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9572 - accuracy: 0.6488\n",
      "Epoch 00005: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1430/1430 [==============================] - 1555s 1s/step - loss: 0.9570 - accuracy: 0.6489 - val_loss: 1.6119 - val_accuracy: 0.4389\n",
      "Epoch 6/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9160 - accuracy: 0.6643\n",
      "Epoch 00006: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "1430/1430 [==============================] - 1555s 1s/step - loss: 0.9158 - accuracy: 0.6644 - val_loss: 1.5127 - val_accuracy: 0.4502\n",
      "Epoch 7/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9103 - accuracy: 0.6659\n",
      "Epoch 00007: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "1430/1430 [==============================] - 1555s 1s/step - loss: 0.9102 - accuracy: 0.6659 - val_loss: 1.6170 - val_accuracy: 0.4286\n",
      "Epoch 8/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9031 - accuracy: 0.6702\n",
      "Epoch 00008: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "1430/1430 [==============================] - 1556s 1s/step - loss: 0.9030 - accuracy: 0.6702 - val_loss: 1.5558 - val_accuracy: 0.4380\n",
      "Epoch 9/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9046 - accuracy: 0.6693\n",
      "Epoch 00009: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1430/1430 [==============================] - 1555s 1s/step - loss: 0.9047 - accuracy: 0.6692 - val_loss: 1.5402 - val_accuracy: 0.4482\n",
      "Epoch 10/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9000 - accuracy: 0.6724\n",
      "Epoch 00010: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "1430/1430 [==============================] - 1556s 1s/step - loss: 0.8999 - accuracy: 0.6725 - val_loss: 1.5365 - val_accuracy: 0.4414\n",
      "Epoch 11/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9001 - accuracy: 0.6725\n",
      "Epoch 00011: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "1430/1430 [==============================] - 1555s 1s/step - loss: 0.9001 - accuracy: 0.6725 - val_loss: 1.5431 - val_accuracy: 0.4397\n",
      "Epoch 12/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.8963 - accuracy: 0.6734\n",
      "Epoch 00012: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "1430/1430 [==============================] - 1556s 1s/step - loss: 0.8962 - accuracy: 0.6735 - val_loss: 1.5276 - val_accuracy: 0.4443\n",
      "Epoch 13/100\n",
      "1429/1430 [============================>.] - ETA: 1s - loss: 0.9003 - accuracy: 0.6747\n",
      "Epoch 00013: saving model to ./insectrec/created_data/weights/model_test_65.h5\n",
      "1430/1430 [==============================] - 1555s 1s/step - loss: 0.9003 - accuracy: 0.6747 - val_loss: 1.5357 - val_accuracy: 0.4417\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:425]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[425:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "FH2 = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n",
    "    epochs=epochs, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
